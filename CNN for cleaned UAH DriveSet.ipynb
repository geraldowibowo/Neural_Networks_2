{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import math\n",
    "\n",
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA (VERSION 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv (r'C:/Users/Geraldo Wibowo/Desktop/Year 4/FYP/JUPYTER TEST 1/11_5_2020/input3.csv', index_col = 0)\n",
    "input_data.index.name = 'Timestamp (seconds)'\n",
    "output_data = pd.read_csv (r'C:/Users/Geraldo Wibowo/Desktop/Year 4/FYP/JUPYTER TEST 1/11_5_2020/output3.csv', index_col = 0)\n",
    "output_data.index.name = 'Timestamp (seconds)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_columns = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_data2 = np.array(output_data)\n",
    "#print(output_data2.shape)\n",
    "\n",
    "#Y = list()\n",
    "\n",
    "#for i in range((int(split_columns/2)),output_data2.shape[0], split_columns):\n",
    "#    Y.append(output_data2[i])\n",
    "\n",
    "#Y = array(Y)\n",
    "#print(Y.shape)\n",
    "\n",
    "#DECODING Y\n",
    "# integer encode direction\n",
    "#encoder = LabelEncoder()\n",
    "#Y = encoder.fit_transform(Y)\n",
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30929, 3)\n"
     ]
    }
   ],
   "source": [
    "#Modifying the output_data to, putting to Y in array\n",
    "#1 0 0 for normal\n",
    "#0 1 0 for drowsy\n",
    "#0 0 1 for aggressive\n",
    "\n",
    "output_data = np.array(output_data)\n",
    "\n",
    "Y = list()\n",
    "\n",
    "for i in range(int(output_data.shape[0]/split_columns)):\n",
    "    condition = output_data[(i*split_columns)]    \n",
    "    behavior = []\n",
    "    if(condition=='DROWSY'):\n",
    "        behavior = [0,1,0]\n",
    "    elif(condition=='AGGRESSIVE'):\n",
    "        behavior = [0,0,1]\n",
    "    else:\n",
    "        behavior = [1,0,0]\n",
    "    \n",
    "    Y.append(behavior)\n",
    "\n",
    "Y = array(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30929, 28)\n",
      "(30929, 3)\n"
     ]
    }
   ],
   "source": [
    "#min max scaler\n",
    "X = input_data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS IF MINMAX SCALER IS NOT USED\n",
    "#X = np.array(X)\n",
    "#X = np.reshape(X,(int(X.shape[0]/split_columns),split_columns,X.shape[1]))\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESHAPING X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30929, 1, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X,(int(X.shape[0]/split_columns),split_columns,X.shape[1],1))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING TRAINING AND TEST DATA METHOD 1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24743, 1, 28, 1)\n",
      "(6186, 1, 28, 1)\n",
      "(24743, 3)\n",
      "(6186, 3)\n"
     ]
    }
   ],
   "source": [
    "#SPLITTING TRAINING AND TEST DATA METHOD 2\n",
    "#X_train = X[:(int(X.shape[0] * 0.8)),:,:]\n",
    "#X_test = X[(int(X.shape[0] * 0.8)):,:,:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#Y_train = Y[:(int(Y.shape[0] * 0.8)),:]\n",
    "#Y_test = Y[(int(Y.shape[0] * 0.8)):,:]\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING SURE DATA TYPE ARE CORRECT\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "Y_train = np.asarray(Y_train).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]) \n",
    "model.add(Conv2D(25, kernel_size=(1,3), strides=(1,1), padding='valid', activation='relu', input_shape = input_shape))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "#adding dropout layer to reduce overfitting\n",
    "model.add(Dropout(0.2))\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1, 26, 25)         100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 26, 25)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               65100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 65,503\n",
      "Trainable params: 65,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.9879 - accuracy: 0.4711 - val_loss: 0.9068 - val_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.8743 - accuracy: 0.5557 - val_loss: 0.8045 - val_accuracy: 0.6106\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.7984 - accuracy: 0.6099 - val_loss: 0.7230 - val_accuracy: 0.6781\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.7485 - accuracy: 0.6399 - val_loss: 0.6701 - val_accuracy: 0.7169\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 1s 4ms/step - loss: 0.6953 - accuracy: 0.6805 - val_loss: 0.6270 - val_accuracy: 0.7425\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.6650 - accuracy: 0.7023 - val_loss: 0.5926 - val_accuracy: 0.7650\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.6389 - accuracy: 0.7186 - val_loss: 0.5797 - val_accuracy: 0.7659\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.7300 - val_loss: 0.5538 - val_accuracy: 0.7756\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.6005 - accuracy: 0.7404 - val_loss: 0.5451 - val_accuracy: 0.7840\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5835 - accuracy: 0.7485 - val_loss: 0.5327 - val_accuracy: 0.7858\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5665 - accuracy: 0.7567 - val_loss: 0.5283 - val_accuracy: 0.7882\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5632 - accuracy: 0.7590 - val_loss: 0.5203 - val_accuracy: 0.7923\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5494 - accuracy: 0.7637 - val_loss: 0.4973 - val_accuracy: 0.8028\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.7706 - val_loss: 0.4866 - val_accuracy: 0.8026\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7721 - val_loss: 0.4785 - val_accuracy: 0.8029\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7748 - val_loss: 0.4881 - val_accuracy: 0.7981\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7812 - val_loss: 0.4558 - val_accuracy: 0.8168\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.7855 - val_loss: 0.4437 - val_accuracy: 0.8254\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4908 - accuracy: 0.7950 - val_loss: 0.4445 - val_accuracy: 0.8212\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.7939 - val_loss: 0.4407 - val_accuracy: 0.8253\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4838 - accuracy: 0.7957 - val_loss: 0.4279 - val_accuracy: 0.8246\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.7964 - val_loss: 0.4359 - val_accuracy: 0.8204\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.8016 - val_loss: 0.4069 - val_accuracy: 0.8424\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.8053 - val_loss: 0.4098 - val_accuracy: 0.8267\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.8092 - val_loss: 0.4060 - val_accuracy: 0.8362\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4496 - accuracy: 0.8096 - val_loss: 0.3934 - val_accuracy: 0.8468\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4442 - accuracy: 0.8158 - val_loss: 0.3785 - val_accuracy: 0.8492\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4367 - accuracy: 0.8157 - val_loss: 0.4005 - val_accuracy: 0.8351\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.8205 - val_loss: 0.3696 - val_accuracy: 0.8550\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4262 - accuracy: 0.8214 - val_loss: 0.3756 - val_accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4179 - accuracy: 0.8252 - val_loss: 0.3732 - val_accuracy: 0.8456\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4138 - accuracy: 0.8268 - val_loss: 0.3648 - val_accuracy: 0.8540\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8266 - val_loss: 0.3534 - val_accuracy: 0.8565\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4080 - accuracy: 0.8288 - val_loss: 0.3355 - val_accuracy: 0.8689\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.4013 - accuracy: 0.8357 - val_loss: 0.3602 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.3974 - accuracy: 0.8363 - val_loss: 0.3324 - val_accuracy: 0.8683\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8376 - val_loss: 0.3468 - val_accuracy: 0.8626\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.3902 - accuracy: 0.8375 - val_loss: 0.3278 - val_accuracy: 0.8716\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3810 - accuracy: 0.8441 - val_loss: 0.3257 - val_accuracy: 0.8716\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.3807 - accuracy: 0.8428 - val_loss: 0.3166 - val_accuracy: 0.8757\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.8404 - val_loss: 0.3099 - val_accuracy: 0.8775\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3709 - accuracy: 0.8450 - val_loss: 0.3058 - val_accuracy: 0.8788\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8493 - val_loss: 0.3003 - val_accuracy: 0.8841\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3659 - accuracy: 0.8499 - val_loss: 0.3020 - val_accuracy: 0.8828\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3591 - accuracy: 0.8528 - val_loss: 0.2934 - val_accuracy: 0.8855\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3548 - accuracy: 0.8526 - val_loss: 0.3128 - val_accuracy: 0.8773\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3542 - accuracy: 0.8522 - val_loss: 0.3205 - val_accuracy: 0.8692\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3539 - accuracy: 0.8544 - val_loss: 0.2850 - val_accuracy: 0.8919\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3454 - accuracy: 0.8580 - val_loss: 0.2892 - val_accuracy: 0.8844\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.3428 - accuracy: 0.8588 - val_loss: 0.2962 - val_accuracy: 0.8784\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3463 - accuracy: 0.8579 - val_loss: 0.2814 - val_accuracy: 0.8904\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3387 - accuracy: 0.8591 - val_loss: 0.2769 - val_accuracy: 0.8894\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3364 - accuracy: 0.8627 - val_loss: 0.2961 - val_accuracy: 0.8881\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.3348 - accuracy: 0.8627 - val_loss: 0.2635 - val_accuracy: 0.8948\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.3273 - accuracy: 0.8672 - val_loss: 0.2670 - val_accuracy: 0.8957\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3291 - accuracy: 0.8662 - val_loss: 0.2660 - val_accuracy: 0.8941\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3277 - accuracy: 0.8676 - val_loss: 0.2737 - val_accuracy: 0.8917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3244 - accuracy: 0.8674 - val_loss: 0.2613 - val_accuracy: 0.9037\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3242 - accuracy: 0.8661 - val_loss: 0.2628 - val_accuracy: 0.8959\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3213 - accuracy: 0.8673 - val_loss: 0.2494 - val_accuracy: 0.9032\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3133 - accuracy: 0.8735 - val_loss: 0.2582 - val_accuracy: 0.9007\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8709 - val_loss: 0.2485 - val_accuracy: 0.9030\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3168 - accuracy: 0.8712 - val_loss: 0.2613 - val_accuracy: 0.8982\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3139 - accuracy: 0.8723 - val_loss: 0.2438 - val_accuracy: 0.9041\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3106 - accuracy: 0.8721 - val_loss: 0.2709 - val_accuracy: 0.8860\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3084 - accuracy: 0.8751 - val_loss: 0.2676 - val_accuracy: 0.8930\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.8770 - val_loss: 0.2454 - val_accuracy: 0.9074\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3077 - accuracy: 0.8752 - val_loss: 0.2354 - val_accuracy: 0.9054\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.3035 - accuracy: 0.8757 - val_loss: 0.2484 - val_accuracy: 0.9046\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.2997 - accuracy: 0.8786 - val_loss: 0.2490 - val_accuracy: 0.8977\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2963 - accuracy: 0.8804 - val_loss: 0.2362 - val_accuracy: 0.9103\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2981 - accuracy: 0.8789 - val_loss: 0.2304 - val_accuracy: 0.9140\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2954 - accuracy: 0.8805 - val_loss: 0.2376 - val_accuracy: 0.9061\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2945 - accuracy: 0.8817 - val_loss: 0.2304 - val_accuracy: 0.9079\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2901 - accuracy: 0.8827 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2900 - accuracy: 0.8824 - val_loss: 0.2201 - val_accuracy: 0.9122\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2878 - accuracy: 0.8851 - val_loss: 0.2185 - val_accuracy: 0.9201\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2916 - accuracy: 0.8805 - val_loss: 0.2607 - val_accuracy: 0.9024\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2832 - accuracy: 0.8840 - val_loss: 0.2127 - val_accuracy: 0.9203\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2874 - accuracy: 0.8813 - val_loss: 0.2200 - val_accuracy: 0.9187\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2862 - accuracy: 0.8835 - val_loss: 0.2251 - val_accuracy: 0.9095\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2781 - accuracy: 0.8869 - val_loss: 0.2450 - val_accuracy: 0.9054\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2780 - accuracy: 0.8887 - val_loss: 0.2185 - val_accuracy: 0.9159\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2782 - accuracy: 0.8875 - val_loss: 0.2116 - val_accuracy: 0.9163\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2730 - accuracy: 0.8893 - val_loss: 0.2217 - val_accuracy: 0.9169\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2770 - accuracy: 0.8869 - val_loss: 0.2267 - val_accuracy: 0.9083\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2803 - accuracy: 0.8861 - val_loss: 0.2099 - val_accuracy: 0.9210\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2694 - accuracy: 0.8907 - val_loss: 0.2737 - val_accuracy: 0.8930\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2731 - accuracy: 0.8893 - val_loss: 0.2005 - val_accuracy: 0.9224\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.8903 - val_loss: 0.2300 - val_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2671 - accuracy: 0.8904 - val_loss: 0.2057 - val_accuracy: 0.9174\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2631 - accuracy: 0.8929 - val_loss: 0.2090 - val_accuracy: 0.9164\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2638 - accuracy: 0.8925 - val_loss: 0.2241 - val_accuracy: 0.9033\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.8929 - val_loss: 0.2006 - val_accuracy: 0.9180\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2621 - accuracy: 0.8951 - val_loss: 0.1963 - val_accuracy: 0.9273\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2662 - accuracy: 0.8908 - val_loss: 0.2256 - val_accuracy: 0.9074\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2599 - accuracy: 0.8925 - val_loss: 0.1960 - val_accuracy: 0.9208\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.2612 - accuracy: 0.8948 - val_loss: 0.2041 - val_accuracy: 0.9279\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2615 - accuracy: 0.8921 - val_loss: 0.2190 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.2572 - accuracy: 0.8955 - val_loss: 0.1992 - val_accuracy: 0.9269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x180f7808c40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=100, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6186, 3)\n",
      "After the predictions has been estimated, the accuracy is 92.69317814419658 %\n"
     ]
    }
   ],
   "source": [
    "check2 = X_test.reshape((X_test.shape[0], X.shape[1], X.shape[2],1))\n",
    "predictions = model.predict(check2)\n",
    "print(predictions.shape)\n",
    "for i in range(predictions.shape[0]):\n",
    "    if (predictions[i][0] >= predictions[i][1] and predictions[i][0] >= predictions[i][2]):\n",
    "        predictions[i] = [1, 0, 0]\n",
    "    elif (predictions[i][1] >= predictions[i][0] and predictions[i][1] >= predictions[i][2]):\n",
    "        predictions[i] = [0, 1, 0]\n",
    "    else:\n",
    "        predictions[i] = [0, 0, 1]\n",
    "\n",
    "\n",
    "        \n",
    "count = 0\n",
    "for i in range(predictions.shape[0]):\n",
    "    if(predictions[i][0] == (Y_test[i][0]) and predictions[i][1] == (Y_test[i][1]) and predictions[i][2] == (Y_test[i][2]) ):\n",
    "        count = count + 1\n",
    "print('After the predictions has been estimated, the accuracy is ' + str((count/predictions.shape[0])*100) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 1.0822 - accuracy: 0.4174 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0803 - accuracy: 0.4200 - val_loss: 1.0759 - val_accuracy: 0.4298\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0789 - accuracy: 0.4215 - val_loss: 1.0735 - val_accuracy: 0.4298\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0791 - accuracy: 0.4215 - val_loss: 1.0740 - val_accuracy: 0.4298\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0749 - val_accuracy: 0.4298\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.4215 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0785 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0738 - val_accuracy: 0.4298\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4215 - val_loss: 1.0766 - val_accuracy: 0.4298\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0751 - val_accuracy: 0.4298\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4215 - val_loss: 1.0752 - val_accuracy: 0.4298\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4215 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0778 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4216 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4215 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4217 - val_loss: 1.0753 - val_accuracy: 0.4298\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0775 - accuracy: 0.4216 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0773 - accuracy: 0.4215 - val_loss: 1.0755 - val_accuracy: 0.4298\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0771 - accuracy: 0.4216 - val_loss: 1.0759 - val_accuracy: 0.4298\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4215 - val_loss: 1.0753 - val_accuracy: 0.4298\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0771 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4216 - val_loss: 1.0751 - val_accuracy: 0.4298\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4216 - val_loss: 1.0758 - val_accuracy: 0.4298\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0768 - accuracy: 0.4217 - val_loss: 1.0749 - val_accuracy: 0.4298\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0769 - accuracy: 0.4217 - val_loss: 1.0761 - val_accuracy: 0.4298\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4217 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0765 - accuracy: 0.4215 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4219 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0764 - accuracy: 0.4215 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0764 - accuracy: 0.4217 - val_loss: 1.0760 - val_accuracy: 0.4298\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0763 - accuracy: 0.4217 - val_loss: 1.0753 - val_accuracy: 0.4298\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0767 - accuracy: 0.4218 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0761 - accuracy: 0.4217 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0759 - accuracy: 0.4216 - val_loss: 1.0757 - val_accuracy: 0.4285\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0760 - accuracy: 0.4219 - val_loss: 1.0752 - val_accuracy: 0.4300\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0762 - accuracy: 0.4216 - val_loss: 1.0749 - val_accuracy: 0.4298\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4221 - val_loss: 1.0745 - val_accuracy: 0.4295\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0754 - accuracy: 0.4221 - val_loss: 1.0756 - val_accuracy: 0.4297\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4221 - val_loss: 1.0765 - val_accuracy: 0.4295\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4223 - val_loss: 1.0749 - val_accuracy: 0.4298\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0753 - accuracy: 0.4223 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0753 - accuracy: 0.4225 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0754 - accuracy: 0.4226 - val_loss: 1.0752 - val_accuracy: 0.4295\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0751 - accuracy: 0.4223 - val_loss: 1.0752 - val_accuracy: 0.4298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0754 - accuracy: 0.4226 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0752 - accuracy: 0.4232 - val_loss: 1.0751 - val_accuracy: 0.4300\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0749 - accuracy: 0.4242 - val_loss: 1.0749 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0750 - accuracy: 0.4225 - val_loss: 1.0752 - val_accuracy: 0.4295\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.4230 - val_loss: 1.0756 - val_accuracy: 0.4284\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0744 - accuracy: 0.4231 - val_loss: 1.0760 - val_accuracy: 0.4295\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0747 - accuracy: 0.4236 - val_loss: 1.0753 - val_accuracy: 0.4297\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0742 - accuracy: 0.4237 - val_loss: 1.0758 - val_accuracy: 0.4294\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0746 - accuracy: 0.4234 - val_loss: 1.0753 - val_accuracy: 0.4302\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0744 - accuracy: 0.4232 - val_loss: 1.0759 - val_accuracy: 0.4295\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0738 - accuracy: 0.4237 - val_loss: 1.0751 - val_accuracy: 0.4292\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0738 - accuracy: 0.4235 - val_loss: 1.0754 - val_accuracy: 0.4287\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4231 - val_loss: 1.0758 - val_accuracy: 0.4303\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4241 - val_loss: 1.0764 - val_accuracy: 0.4295\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4229 - val_loss: 1.0767 - val_accuracy: 0.4284\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0734 - accuracy: 0.4242 - val_loss: 1.0757 - val_accuracy: 0.4284\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4240 - val_loss: 1.0768 - val_accuracy: 0.4297\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0737 - accuracy: 0.4239 - val_loss: 1.0757 - val_accuracy: 0.4290\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0735 - accuracy: 0.4245 - val_loss: 1.0762 - val_accuracy: 0.4294\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0730 - accuracy: 0.4240 - val_loss: 1.0763 - val_accuracy: 0.4269\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0731 - accuracy: 0.4239 - val_loss: 1.0775 - val_accuracy: 0.4255\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0725 - accuracy: 0.4243 - val_loss: 1.0760 - val_accuracy: 0.4303\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0730 - accuracy: 0.4238 - val_loss: 1.0759 - val_accuracy: 0.4292\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0726 - accuracy: 0.4250 - val_loss: 1.0765 - val_accuracy: 0.4276\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0726 - accuracy: 0.4249 - val_loss: 1.0768 - val_accuracy: 0.4273\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0725 - accuracy: 0.4243 - val_loss: 1.0761 - val_accuracy: 0.4305\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0727 - accuracy: 0.4252 - val_loss: 1.0761 - val_accuracy: 0.4276\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0726 - accuracy: 0.4250 - val_loss: 1.0766 - val_accuracy: 0.4298\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0714 - accuracy: 0.4254 - val_loss: 1.0794 - val_accuracy: 0.4247\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0724 - accuracy: 0.4243 - val_loss: 1.0767 - val_accuracy: 0.4282\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0719 - accuracy: 0.4259 - val_loss: 1.0779 - val_accuracy: 0.4268\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0721 - accuracy: 0.4263 - val_loss: 1.0771 - val_accuracy: 0.4256\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0713 - accuracy: 0.4266 - val_loss: 1.0791 - val_accuracy: 0.4252\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0712 - accuracy: 0.4261 - val_loss: 1.0786 - val_accuracy: 0.4240\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0716 - accuracy: 0.4249 - val_loss: 1.0774 - val_accuracy: 0.4269\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0715 - accuracy: 0.4258 - val_loss: 1.0781 - val_accuracy: 0.4261\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0709 - accuracy: 0.4281 - val_loss: 1.0779 - val_accuracy: 0.4273\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0713 - accuracy: 0.4252 - val_loss: 1.0773 - val_accuracy: 0.4303\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0711 - accuracy: 0.4259 - val_loss: 1.0784 - val_accuracy: 0.4235\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0709 - accuracy: 0.4255 - val_loss: 1.0783 - val_accuracy: 0.4274\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0704 - accuracy: 0.4262 - val_loss: 1.0782 - val_accuracy: 0.4273\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0701 - accuracy: 0.4270 - val_loss: 1.0791 - val_accuracy: 0.4260\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0706 - accuracy: 0.4260 - val_loss: 1.0789 - val_accuracy: 0.4235\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 1.0812 - accuracy: 0.4194 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0794 - accuracy: 0.4214 - val_loss: 1.0736 - val_accuracy: 0.4298\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0788 - accuracy: 0.4215 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0792 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0738 - val_accuracy: 0.4298\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.4215 - val_loss: 1.0770 - val_accuracy: 0.4298\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0784 - accuracy: 0.4215 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.4215 - val_loss: 1.0740 - val_accuracy: 0.4298\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0757 - val_accuracy: 0.4298\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0740 - val_accuracy: 0.4298\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4215 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4215 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4215 - val_loss: 1.0747 - val_accuracy: 0.4298\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0776 - accuracy: 0.4215 - val_loss: 1.0753 - val_accuracy: 0.4298\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4214 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4215 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0773 - accuracy: 0.4217 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0775 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4215 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4216 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0772 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0770 - accuracy: 0.4215 - val_loss: 1.0751 - val_accuracy: 0.4298\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0769 - accuracy: 0.4219 - val_loss: 1.0755 - val_accuracy: 0.4298\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0769 - accuracy: 0.4216 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4214 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0769 - accuracy: 0.4219 - val_loss: 1.0750 - val_accuracy: 0.4298\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0762 - accuracy: 0.4212 - val_loss: 1.0762 - val_accuracy: 0.4298\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0767 - accuracy: 0.4218 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0764 - accuracy: 0.4218 - val_loss: 1.0747 - val_accuracy: 0.4292\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0763 - accuracy: 0.4212 - val_loss: 1.0746 - val_accuracy: 0.4300\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0765 - accuracy: 0.4216 - val_loss: 1.0751 - val_accuracy: 0.4298\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0761 - accuracy: 0.4218 - val_loss: 1.0747 - val_accuracy: 0.4292\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0763 - accuracy: 0.4216 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0760 - accuracy: 0.4222 - val_loss: 1.0754 - val_accuracy: 0.4294\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0763 - accuracy: 0.4222 - val_loss: 1.0764 - val_accuracy: 0.4290\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0759 - accuracy: 0.4225 - val_loss: 1.0749 - val_accuracy: 0.4298\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0756 - accuracy: 0.4225 - val_loss: 1.0754 - val_accuracy: 0.4298\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0753 - accuracy: 0.4223 - val_loss: 1.0752 - val_accuracy: 0.4294\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4220 - val_loss: 1.0748 - val_accuracy: 0.4300\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0755 - accuracy: 0.4226 - val_loss: 1.0755 - val_accuracy: 0.4277\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0751 - accuracy: 0.4234 - val_loss: 1.0753 - val_accuracy: 0.4295\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0753 - accuracy: 0.4223 - val_loss: 1.0765 - val_accuracy: 0.4300\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0754 - accuracy: 0.4227 - val_loss: 1.0754 - val_accuracy: 0.4295\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0749 - accuracy: 0.4238 - val_loss: 1.0763 - val_accuracy: 0.4273\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0746 - accuracy: 0.4236 - val_loss: 1.0778 - val_accuracy: 0.4292\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0745 - accuracy: 0.4230 - val_loss: 1.0758 - val_accuracy: 0.4298\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.4219 - val_loss: 1.0764 - val_accuracy: 0.4297\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.4240 - val_loss: 1.0766 - val_accuracy: 0.4294\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0746 - accuracy: 0.4228 - val_loss: 1.0755 - val_accuracy: 0.4298\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0744 - accuracy: 0.4238 - val_loss: 1.0754 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0739 - accuracy: 0.4230 - val_loss: 1.0761 - val_accuracy: 0.4297\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4242 - val_loss: 1.0756 - val_accuracy: 0.4300\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0739 - accuracy: 0.4235 - val_loss: 1.0766 - val_accuracy: 0.4279\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4247 - val_loss: 1.0761 - val_accuracy: 0.4303\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0733 - accuracy: 0.4248 - val_loss: 1.0778 - val_accuracy: 0.4292\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0735 - accuracy: 0.4239 - val_loss: 1.0785 - val_accuracy: 0.4253\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4236 - val_loss: 1.0773 - val_accuracy: 0.4268\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0732 - accuracy: 0.4244 - val_loss: 1.0773 - val_accuracy: 0.4271\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0735 - accuracy: 0.4231 - val_loss: 1.0763 - val_accuracy: 0.4298\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0732 - accuracy: 0.4232 - val_loss: 1.0779 - val_accuracy: 0.4260\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 1.0725 - accuracy: 0.4237 - val_loss: 1.0774 - val_accuracy: 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 1.0731 - accuracy: 0.4250 - val_loss: 1.0780 - val_accuracy: 0.4266\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0728 - accuracy: 0.4240 - val_loss: 1.0772 - val_accuracy: 0.4285\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0729 - accuracy: 0.4249 - val_loss: 1.0772 - val_accuracy: 0.4271\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0723 - accuracy: 0.4243 - val_loss: 1.0760 - val_accuracy: 0.4294\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0719 - accuracy: 0.4264 - val_loss: 1.0781 - val_accuracy: 0.4261\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0725 - accuracy: 0.4254 - val_loss: 1.0773 - val_accuracy: 0.4289\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0707 - accuracy: 0.4263 - val_loss: 1.0808 - val_accuracy: 0.4232\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0723 - accuracy: 0.4261 - val_loss: 1.0773 - val_accuracy: 0.4273\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0715 - accuracy: 0.4257 - val_loss: 1.0790 - val_accuracy: 0.4284\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0715 - accuracy: 0.4257 - val_loss: 1.0774 - val_accuracy: 0.4269\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0715 - accuracy: 0.4251 - val_loss: 1.0787 - val_accuracy: 0.4242\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0714 - accuracy: 0.4268 - val_loss: 1.0789 - val_accuracy: 0.4277\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0710 - accuracy: 0.4262 - val_loss: 1.0794 - val_accuracy: 0.4240\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0712 - accuracy: 0.4257 - val_loss: 1.0780 - val_accuracy: 0.4250\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.4275 - val_loss: 1.0799 - val_accuracy: 0.4237\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0707 - accuracy: 0.4266 - val_loss: 1.0794 - val_accuracy: 0.4227\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0707 - accuracy: 0.4253 - val_loss: 1.0790 - val_accuracy: 0.4277\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.4250 - val_loss: 1.0813 - val_accuracy: 0.4242\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0700 - accuracy: 0.4271 - val_loss: 1.0788 - val_accuracy: 0.4218\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0703 - accuracy: 0.4267 - val_loss: 1.0793 - val_accuracy: 0.4276\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.4272 - val_loss: 1.0793 - val_accuracy: 0.4239\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0701 - accuracy: 0.4257 - val_loss: 1.0786 - val_accuracy: 0.4282\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0698 - accuracy: 0.4269 - val_loss: 1.0795 - val_accuracy: 0.4284\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0698 - accuracy: 0.4281 - val_loss: 1.0793 - val_accuracy: 0.4284\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0689 - accuracy: 0.4274 - val_loss: 1.0801 - val_accuracy: 0.4240\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0692 - accuracy: 0.4260 - val_loss: 1.0791 - val_accuracy: 0.4276\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0697 - accuracy: 0.4277 - val_loss: 1.0777 - val_accuracy: 0.4279\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0693 - accuracy: 0.4278 - val_loss: 1.0795 - val_accuracy: 0.4269\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0688 - accuracy: 0.4285 - val_loss: 1.0799 - val_accuracy: 0.4261\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 1.0825 - accuracy: 0.4167 - val_loss: 1.0764 - val_accuracy: 0.4298\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0794 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0790 - accuracy: 0.4215 - val_loss: 1.0770 - val_accuracy: 0.4298\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0785 - accuracy: 0.4215 - val_loss: 1.0736 - val_accuracy: 0.4298\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0785 - accuracy: 0.4215 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.4215 - val_loss: 1.0739 - val_accuracy: 0.4298\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0785 - accuracy: 0.4215 - val_loss: 1.0735 - val_accuracy: 0.4298\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0791 - val_accuracy: 0.4300\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.4215 - val_loss: 1.0739 - val_accuracy: 0.4298\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4214 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0735 - val_accuracy: 0.4298\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4215 - val_loss: 1.0736 - val_accuracy: 0.4298\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4215 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4214 - val_loss: 1.0736 - val_accuracy: 0.4298\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4214 - val_loss: 1.0739 - val_accuracy: 0.4298\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4214 - val_loss: 1.0739 - val_accuracy: 0.4298\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4215 - val_loss: 1.0734 - val_accuracy: 0.4298\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0776 - accuracy: 0.4215 - val_loss: 1.0742 - val_accuracy: 0.4298\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4215 - val_loss: 1.0739 - val_accuracy: 0.4294\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.4216 - val_loss: 1.0735 - val_accuracy: 0.4298\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4217 - val_loss: 1.0755 - val_accuracy: 0.4300\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0776 - accuracy: 0.4219 - val_loss: 1.0741 - val_accuracy: 0.4298\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0779 - accuracy: 0.4218 - val_loss: 1.0738 - val_accuracy: 0.4303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4221 - val_loss: 1.0742 - val_accuracy: 0.4302\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0776 - accuracy: 0.4223 - val_loss: 1.0738 - val_accuracy: 0.4300\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4219 - val_loss: 1.0743 - val_accuracy: 0.4302\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0773 - accuracy: 0.4220 - val_loss: 1.0738 - val_accuracy: 0.4300\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0773 - accuracy: 0.4217 - val_loss: 1.0738 - val_accuracy: 0.4302\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0773 - accuracy: 0.4213 - val_loss: 1.0736 - val_accuracy: 0.4300\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0771 - accuracy: 0.4225 - val_loss: 1.0735 - val_accuracy: 0.4300\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4222 - val_loss: 1.0734 - val_accuracy: 0.4300\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4225 - val_loss: 1.0732 - val_accuracy: 0.4300\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0771 - accuracy: 0.4227 - val_loss: 1.0738 - val_accuracy: 0.4302\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0765 - accuracy: 0.4228 - val_loss: 1.0749 - val_accuracy: 0.4297\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4229 - val_loss: 1.0734 - val_accuracy: 0.4300\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0768 - accuracy: 0.4220 - val_loss: 1.0739 - val_accuracy: 0.4300\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4223 - val_loss: 1.0737 - val_accuracy: 0.4297\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0765 - accuracy: 0.4231 - val_loss: 1.0735 - val_accuracy: 0.4298\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0763 - accuracy: 0.4226 - val_loss: 1.0738 - val_accuracy: 0.4300\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4225 - val_loss: 1.0744 - val_accuracy: 0.4300\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0759 - accuracy: 0.4233 - val_loss: 1.0765 - val_accuracy: 0.4295\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0762 - accuracy: 0.4233 - val_loss: 1.0735 - val_accuracy: 0.4297\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4223 - val_loss: 1.0730 - val_accuracy: 0.4297\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0757 - accuracy: 0.4234 - val_loss: 1.0741 - val_accuracy: 0.4295\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0755 - accuracy: 0.4235 - val_loss: 1.0748 - val_accuracy: 0.4295\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0756 - accuracy: 0.4237 - val_loss: 1.0743 - val_accuracy: 0.4290\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0754 - accuracy: 0.4230 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0755 - accuracy: 0.4228 - val_loss: 1.0737 - val_accuracy: 0.4297\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0748 - accuracy: 0.4239 - val_loss: 1.0737 - val_accuracy: 0.4292\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0752 - accuracy: 0.4227 - val_loss: 1.0755 - val_accuracy: 0.4290\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0747 - accuracy: 0.4236 - val_loss: 1.0759 - val_accuracy: 0.4268\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0748 - accuracy: 0.4229 - val_loss: 1.0747 - val_accuracy: 0.4294\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0746 - accuracy: 0.4231 - val_loss: 1.0743 - val_accuracy: 0.4298\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0749 - accuracy: 0.4248 - val_loss: 1.0756 - val_accuracy: 0.4277\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0747 - accuracy: 0.4235 - val_loss: 1.0748 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0742 - accuracy: 0.4244 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0741 - accuracy: 0.4240 - val_loss: 1.0743 - val_accuracy: 0.4287\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0739 - accuracy: 0.4241 - val_loss: 1.0743 - val_accuracy: 0.4290\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0741 - accuracy: 0.4247 - val_loss: 1.0757 - val_accuracy: 0.4268\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0736 - accuracy: 0.4235 - val_loss: 1.0746 - val_accuracy: 0.4300\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0737 - accuracy: 0.4243 - val_loss: 1.0758 - val_accuracy: 0.4279\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0735 - accuracy: 0.4261 - val_loss: 1.0746 - val_accuracy: 0.4292\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0734 - accuracy: 0.4253 - val_loss: 1.0758 - val_accuracy: 0.4264\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0734 - accuracy: 0.4253 - val_loss: 1.0750 - val_accuracy: 0.4289\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0731 - accuracy: 0.4261 - val_loss: 1.0760 - val_accuracy: 0.4258\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0730 - accuracy: 0.4250 - val_loss: 1.0763 - val_accuracy: 0.4237\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0730 - accuracy: 0.4251 - val_loss: 1.0756 - val_accuracy: 0.4266\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0726 - accuracy: 0.4257 - val_loss: 1.0756 - val_accuracy: 0.4279\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0721 - accuracy: 0.4254 - val_loss: 1.0760 - val_accuracy: 0.4282\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0721 - accuracy: 0.4247 - val_loss: 1.0761 - val_accuracy: 0.4287\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0723 - accuracy: 0.4273 - val_loss: 1.0766 - val_accuracy: 0.4237\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 1s 5ms/step - loss: 1.0719 - accuracy: 0.4268 - val_loss: 1.0757 - val_accuracy: 0.4282\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0719 - accuracy: 0.4267 - val_loss: 1.0762 - val_accuracy: 0.4268\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0714 - accuracy: 0.4250 - val_loss: 1.0769 - val_accuracy: 0.4243\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0713 - accuracy: 0.4258 - val_loss: 1.0771 - val_accuracy: 0.4281\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0712 - accuracy: 0.4258 - val_loss: 1.0762 - val_accuracy: 0.4264\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0710 - accuracy: 0.4277 - val_loss: 1.0777 - val_accuracy: 0.4243\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0702 - accuracy: 0.4284 - val_loss: 1.0786 - val_accuracy: 0.4190\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0705 - accuracy: 0.4274 - val_loss: 1.0769 - val_accuracy: 0.4253\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0707 - accuracy: 0.4276 - val_loss: 1.0775 - val_accuracy: 0.4255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.4265 - val_loss: 1.0761 - val_accuracy: 0.4264\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0707 - accuracy: 0.4285 - val_loss: 1.0769 - val_accuracy: 0.4222\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0701 - accuracy: 0.4273 - val_loss: 1.0768 - val_accuracy: 0.4264\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0701 - accuracy: 0.4281 - val_loss: 1.0784 - val_accuracy: 0.4231\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0700 - accuracy: 0.4279 - val_loss: 1.0780 - val_accuracy: 0.4239\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0699 - accuracy: 0.4277 - val_loss: 1.0786 - val_accuracy: 0.4235\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0698 - accuracy: 0.4258 - val_loss: 1.0778 - val_accuracy: 0.4261\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0695 - accuracy: 0.4273 - val_loss: 1.0786 - val_accuracy: 0.4253\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0689 - accuracy: 0.4280 - val_loss: 1.0785 - val_accuracy: 0.4263\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0693 - accuracy: 0.4261 - val_loss: 1.0780 - val_accuracy: 0.4237\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0682 - accuracy: 0.4285 - val_loss: 1.0784 - val_accuracy: 0.4243\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0680 - accuracy: 0.4294 - val_loss: 1.0814 - val_accuracy: 0.4206\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0684 - accuracy: 0.4274 - val_loss: 1.0832 - val_accuracy: 0.4180\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0683 - accuracy: 0.4301 - val_loss: 1.0805 - val_accuracy: 0.4222\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0675 - accuracy: 0.4301 - val_loss: 1.0795 - val_accuracy: 0.4218\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 1.0805 - accuracy: 0.4200 - val_loss: 1.0731 - val_accuracy: 0.4298\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0795 - accuracy: 0.4215 - val_loss: 1.0733 - val_accuracy: 0.4298\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0788 - accuracy: 0.4215 - val_loss: 1.0737 - val_accuracy: 0.4298\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0733 - val_accuracy: 0.4298\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0787 - accuracy: 0.4215 - val_loss: 1.0746 - val_accuracy: 0.4298\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0784 - accuracy: 0.4215 - val_loss: 1.0732 - val_accuracy: 0.4298\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.4217 - val_loss: 1.0748 - val_accuracy: 0.4298\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0734 - val_accuracy: 0.4298\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0734 - val_accuracy: 0.4298\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4213 - val_loss: 1.0736 - val_accuracy: 0.4298\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4213 - val_loss: 1.0739 - val_accuracy: 0.4302\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.4215 - val_loss: 1.0732 - val_accuracy: 0.4295\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4216 - val_loss: 1.0732 - val_accuracy: 0.4295\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4217 - val_loss: 1.0735 - val_accuracy: 0.4295\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0782 - accuracy: 0.4217 - val_loss: 1.0745 - val_accuracy: 0.4300\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0780 - accuracy: 0.4214 - val_loss: 1.0737 - val_accuracy: 0.4303\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0782 - accuracy: 0.4218 - val_loss: 1.0739 - val_accuracy: 0.4295\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0781 - accuracy: 0.4217 - val_loss: 1.0738 - val_accuracy: 0.4295\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4216 - val_loss: 1.0740 - val_accuracy: 0.4295\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4217 - val_loss: 1.0768 - val_accuracy: 0.4295\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0778 - accuracy: 0.4218 - val_loss: 1.0741 - val_accuracy: 0.4305\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0779 - accuracy: 0.4219 - val_loss: 1.0745 - val_accuracy: 0.4303\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0778 - accuracy: 0.4221 - val_loss: 1.0734 - val_accuracy: 0.4297\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0775 - accuracy: 0.4217 - val_loss: 1.0737 - val_accuracy: 0.4295\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0774 - accuracy: 0.4219 - val_loss: 1.0738 - val_accuracy: 0.4303\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0775 - accuracy: 0.4219 - val_loss: 1.0744 - val_accuracy: 0.4294\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0774 - accuracy: 0.4220 - val_loss: 1.0739 - val_accuracy: 0.4294\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0773 - accuracy: 0.4217 - val_loss: 1.0744 - val_accuracy: 0.4302\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4221 - val_loss: 1.0745 - val_accuracy: 0.4303\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.4223 - val_loss: 1.0747 - val_accuracy: 0.4302\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0772 - accuracy: 0.4223 - val_loss: 1.0745 - val_accuracy: 0.4300\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0771 - accuracy: 0.4217 - val_loss: 1.0742 - val_accuracy: 0.4305\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0769 - accuracy: 0.4219 - val_loss: 1.0745 - val_accuracy: 0.4298\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0767 - accuracy: 0.4225 - val_loss: 1.0755 - val_accuracy: 0.4298\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0765 - accuracy: 0.4221 - val_loss: 1.0751 - val_accuracy: 0.4308\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4220 - val_loss: 1.0749 - val_accuracy: 0.4302\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.4220 - val_loss: 1.0757 - val_accuracy: 0.4302\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0764 - accuracy: 0.4221 - val_loss: 1.0753 - val_accuracy: 0.4305\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0763 - accuracy: 0.4225 - val_loss: 1.0757 - val_accuracy: 0.4292\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0763 - accuracy: 0.4223 - val_loss: 1.0765 - val_accuracy: 0.4300\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0764 - accuracy: 0.4225 - val_loss: 1.0765 - val_accuracy: 0.4310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0761 - accuracy: 0.4222 - val_loss: 1.0763 - val_accuracy: 0.4305\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0761 - accuracy: 0.4217 - val_loss: 1.0796 - val_accuracy: 0.4313\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0758 - accuracy: 0.4238 - val_loss: 1.0755 - val_accuracy: 0.4305\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0758 - accuracy: 0.4223 - val_loss: 1.0764 - val_accuracy: 0.4316\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0759 - accuracy: 0.4224 - val_loss: 1.0775 - val_accuracy: 0.4321\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0753 - accuracy: 0.4234 - val_loss: 1.0770 - val_accuracy: 0.4315\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0758 - accuracy: 0.4228 - val_loss: 1.0772 - val_accuracy: 0.4316\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0755 - accuracy: 0.4234 - val_loss: 1.0775 - val_accuracy: 0.4315\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0750 - accuracy: 0.4233 - val_loss: 1.0787 - val_accuracy: 0.4318\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0748 - accuracy: 0.4229 - val_loss: 1.0776 - val_accuracy: 0.4311\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0748 - accuracy: 0.4231 - val_loss: 1.0778 - val_accuracy: 0.4321\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0747 - accuracy: 0.4236 - val_loss: 1.0789 - val_accuracy: 0.4303\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0748 - accuracy: 0.4234 - val_loss: 1.0797 - val_accuracy: 0.4315\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.4229 - val_loss: 1.0804 - val_accuracy: 0.4316\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.4236 - val_loss: 1.0795 - val_accuracy: 0.4303\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0737 - accuracy: 0.4231 - val_loss: 1.0794 - val_accuracy: 0.4313\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0735 - accuracy: 0.4247 - val_loss: 1.0802 - val_accuracy: 0.4313\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0736 - accuracy: 0.4240 - val_loss: 1.0808 - val_accuracy: 0.4274\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0734 - accuracy: 0.4227 - val_loss: 1.0809 - val_accuracy: 0.4313\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - ETA: 0s - loss: 1.0726 - accuracy: 0.42 - 1s 6ms/step - loss: 1.0730 - accuracy: 0.4249 - val_loss: 1.0818 - val_accuracy: 0.4316\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0731 - accuracy: 0.4234 - val_loss: 1.0796 - val_accuracy: 0.4332\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0730 - accuracy: 0.4235 - val_loss: 1.0820 - val_accuracy: 0.4311\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0730 - accuracy: 0.4238 - val_loss: 1.0827 - val_accuracy: 0.4313\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0723 - accuracy: 0.4242 - val_loss: 1.0816 - val_accuracy: 0.4313\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0726 - accuracy: 0.4248 - val_loss: 1.0794 - val_accuracy: 0.4298\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0723 - accuracy: 0.4250 - val_loss: 1.0830 - val_accuracy: 0.4289\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0722 - accuracy: 0.4243 - val_loss: 1.0829 - val_accuracy: 0.4260\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0718 - accuracy: 0.4267 - val_loss: 1.0840 - val_accuracy: 0.4298\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0714 - accuracy: 0.4262 - val_loss: 1.0846 - val_accuracy: 0.4289\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0717 - accuracy: 0.4221 - val_loss: 1.0830 - val_accuracy: 0.4295\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0709 - accuracy: 0.4255 - val_loss: 1.0849 - val_accuracy: 0.4290\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0715 - accuracy: 0.4239 - val_loss: 1.0842 - val_accuracy: 0.4285\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0711 - accuracy: 0.4233 - val_loss: 1.0846 - val_accuracy: 0.4306\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0713 - accuracy: 0.4250 - val_loss: 1.0854 - val_accuracy: 0.4302\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.4262 - val_loss: 1.0836 - val_accuracy: 0.4297\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0700 - accuracy: 0.4267 - val_loss: 1.0860 - val_accuracy: 0.4308\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0698 - accuracy: 0.4258 - val_loss: 1.0858 - val_accuracy: 0.4295\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0698 - accuracy: 0.4265 - val_loss: 1.0874 - val_accuracy: 0.4222\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0706 - accuracy: 0.4250 - val_loss: 1.0866 - val_accuracy: 0.4250\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0698 - accuracy: 0.4265 - val_loss: 1.0877 - val_accuracy: 0.4205\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0702 - accuracy: 0.4267 - val_loss: 1.0880 - val_accuracy: 0.4311\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0688 - accuracy: 0.4271 - val_loss: 1.0909 - val_accuracy: 0.4284\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0701 - accuracy: 0.4255 - val_loss: 1.0893 - val_accuracy: 0.4273\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0697 - accuracy: 0.4274 - val_loss: 1.0878 - val_accuracy: 0.4250\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0686 - accuracy: 0.4276 - val_loss: 1.0913 - val_accuracy: 0.4289\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0691 - accuracy: 0.4281 - val_loss: 1.0895 - val_accuracy: 0.4227\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 1.0682 - accuracy: 0.4293 - val_loss: 1.0899 - val_accuracy: 0.4224\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0687 - accuracy: 0.4277 - val_loss: 1.0922 - val_accuracy: 0.4300\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0683 - accuracy: 0.4277 - val_loss: 1.0910 - val_accuracy: 0.4239\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0684 - accuracy: 0.4277 - val_loss: 1.0929 - val_accuracy: 0.4250\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 1.0677 - accuracy: 0.4292 - val_loss: 1.0940 - val_accuracy: 0.4219\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0679 - accuracy: 0.4284 - val_loss: 1.0928 - val_accuracy: 0.4260\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 1.0671 - accuracy: 0.4297 - val_loss: 1.0914 - val_accuracy: 0.4239\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 1.0668 - accuracy: 0.4283 - val_loss: 1.0968 - val_accuracy: 0.4276\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0674 - accuracy: 0.4299 - val_loss: 1.0946 - val_accuracy: 0.4298\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 1.0676 - accuracy: 0.4275 - val_loss: 1.0950 - val_accuracy: 0.4224\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 2s 8ms/step - loss: 1.0674 - accuracy: 0.4290 - val_loss: 1.0945 - val_accuracy: 0.4234\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 1.0667 - accuracy: 0.4285 - val_loss: 1.0942 - val_accuracy: 0.4271\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 24744\n  y sizes: 24743\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-56fa4eb772bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# training the model for 10 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0my_train_data_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 24744\n  y sizes: 24743\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "list_training_error = []\n",
    "list_testing_error = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "   \n",
    "    # building a linear stack of layers with the sequential model\n",
    "    model = Sequential()\n",
    "    # convolutional layer\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]) \n",
    "    model.add(Conv2D(25, kernel_size=(1,3), strides=(1,1), padding='valid', activation='relu', input_shape = input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(1,1)))\n",
    "    # flatten output of conv\n",
    "    model.add(Flatten())\n",
    "    #adding dropout layer to reduce overfitting\n",
    "    model.add(Dropout(0.2))\n",
    "    # hidden layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # compiling the sequential model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    # training the model for 10 epochs\n",
    "    model.fit(X_train, Y_train, batch_size=128, epochs=100, validation_data=(X_test, Y_test))\n",
    "    \n",
    "    y_train_data_pred = model.predict(X_train)\n",
    "    y_test_data_pred = model.predict(X_test)\n",
    "    fold_training_error = mean_absolute_error(y_train, y_train_data_pred) \n",
    "    fold_testing_error = mean_absolute_error(y_test, y_test_data_pred)\n",
    "    list_training_error.append(fold_training_error)\n",
    "    list_testing_error.append(fold_testing_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1, kf.get_n_splits()), np.array(list_training_error).ravel(), 'o-')\n",
    "plt.xlabel('number of fold')\n",
    "plt.ylabel('training error')\n",
    "plt.title('Training error across folds')\n",
    "plt.tight_layout()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, kf.get_n_splits()), np.array(list_testing_error).ravel(), 'o-')\n",
    "plt.xlabel('number of fold')\n",
    "plt.ylabel('testing error')\n",
    "plt.title('Testing error across folds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
