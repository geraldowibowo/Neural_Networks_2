{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import math\n",
    "\n",
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA (VERSION 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv (r'C:/Users/Geraldo Wibowo/Desktop/Year 4/FYP/JUPYTER TEST 1/11_5_2020/input3.csv', index_col = 0)\n",
    "input_data.index.name = 'Timestamp (seconds)'\n",
    "output_data = pd.read_csv (r'C:/Users/Geraldo Wibowo/Desktop/Year 4/FYP/JUPYTER TEST 1/11_5_2020/output3.csv', index_col = 0)\n",
    "output_data.index.name = 'Timestamp (seconds)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y ENCODED TO 1 ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.999 ]\n",
      " [0.999 ]\n",
      " [0.999 ]\n",
      " ...\n",
      " [0.4995]\n",
      " [0.4995]\n",
      " [0.4995]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geraldo Wibowo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "split_columns = 1\n",
    "\n",
    "output_data2 = np.array(output_data)\n",
    "# print(output_data2.shape)\n",
    "\n",
    "Y = list()\n",
    "\n",
    "for i in range((int(split_columns/2)),output_data2.shape[0], split_columns):\n",
    "    Y.append(output_data2[i])\n",
    "\n",
    "Y = array(Y)\n",
    "# print(Y.shape)\n",
    "\n",
    "#DECODING Y\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "Y = np.reshape(Y,(-1,1))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.999))\n",
    "Y = scaler.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying the output_data to, putting to Y in array\n",
    "#1 0 0 for normal\n",
    "#0 1 0 for drowsy\n",
    "#0 0 1 for aggressive\n",
    "\n",
    "# output_data = np.array(output_data)\n",
    "\n",
    "# Y = list()\n",
    "\n",
    "# for i in range(int(output_data.shape[0]/split_columns)):\n",
    "#    condition = output_data[(i*split_columns)]    \n",
    "#    behavior = []\n",
    "#    if(condition=='DROWSY'):\n",
    "#        behavior = [0,1,0]\n",
    "#    elif(condition=='AGGRESSIVE'):\n",
    "#        behavior = [0,0,1]\n",
    "#    else:\n",
    "#        behavior = [1,0,0]\n",
    "    \n",
    "#    Y.append(behavior)\n",
    "\n",
    "# Y = array(Y)\n",
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30929, 28)\n",
      "(30929, 1)\n"
     ]
    }
   ],
   "source": [
    "#min max scaler\n",
    "X = input_data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS IF MINMAX SCALER IS NOT USED\n",
    "#X = np.array(X)\n",
    "#X = np.reshape(X,(int(X.shape[0]/split_columns),split_columns,X.shape[1]))\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESHAPING X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30929, 1, 28)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X,(int(X.shape[0]/split_columns),split_columns,X.shape[1]))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING TRAINING AND TEST DATA METHOD 1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24743, 1, 28)\n",
      "(6186, 1, 28)\n",
      "(24743, 1)\n",
      "(6186, 1)\n"
     ]
    }
   ],
   "source": [
    "#SPLITTING TRAINING AND TEST DATA METHOD 2\n",
    "#X_train = X[:(int(X.shape[0] * 0.8)),:,:]\n",
    "#X_test = X[(int(X.shape[0] * 0.8)):,:,:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#Y_train = Y[:(int(Y.shape[0] * 0.8)),:]\n",
    "#Y_test = Y[(int(Y.shape[0] * 0.8)):,:]\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING SURE DATA TYPE ARE CORRECT\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "Y_train = np.asarray(Y_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESHAPING X_TRAIN\n",
    "#nsamples, nx, ny = X_train.shape\n",
    "#X_train2 = X_train.reshape((nsamples,nx*ny))\n",
    "#THIS NUMBER IS THE INPUT LAYER (23200)\n",
    "#print(X_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESHAPING X_TEST\n",
    "#nsamples, nx, ny = X_test.shape\n",
    "#X_test2 = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_6:0\", shape=(None, 1, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Model\n",
    "inputs = KL.Input(shape=(split_columns, X_train.shape[2]))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"simple_rnn_5/strided_slice_3:0\", shape=(None, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# For RNN\n",
    "x = KL.SimpleRNN(100, activation ='relu')(inputs) \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_5/Softmax:0\", shape=(None, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = KL.Dense(3, activation=\"softmax\")(x)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 1, 28)]           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 13,203\n",
      "Trainable params: 13,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "774/774 [==============================] - 1s 965us/step - loss: 0.9872 - acc: 0.4688\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 1s 899us/step - loss: 0.8865 - acc: 0.5431\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - 1s 829us/step - loss: 0.8141 - acc: 0.6041\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 1s 836us/step - loss: 0.7682 - acc: 0.6461\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 1s 832us/step - loss: 0.7356 - acc: 0.6682\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 1s 823us/step - loss: 0.7106 - acc: 0.6863\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 1s 867us/step - loss: 0.6907 - acc: 0.6979\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 1s 899us/step - loss: 0.6735 - acc: 0.7092\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - 1s 908us/step - loss: 0.6563 - acc: 0.7188\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 1s 899us/step - loss: 0.6416 - acc: 0.7261\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 1s 917us/step - loss: 0.6279 - acc: 0.7341\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 1s 893us/step - loss: 0.6135 - acc: 0.7417\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 1s 896us/step - loss: 0.6001 - acc: 0.7452\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 1s 905us/step - loss: 0.5883 - acc: 0.7533\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 1s 908us/step - loss: 0.5780 - acc: 0.7574\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 1s 894us/step - loss: 0.5673 - acc: 0.7605\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 1s 908us/step - loss: 0.5582 - acc: 0.7670\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 1s 867us/step - loss: 0.5481 - acc: 0.7734\n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 1s 863us/step - loss: 0.5380 - acc: 0.7766\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 1s 894us/step - loss: 0.5341 - acc: 0.7768\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 1s 901us/step - loss: 0.5266 - acc: 0.7798\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 1s 895us/step - loss: 0.5181 - acc: 0.7838\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 1s 912us/step - loss: 0.5114 - acc: 0.7865\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 1s 896us/step - loss: 0.5033 - acc: 0.7945\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 1s 894us/step - loss: 0.5006 - acc: 0.7907\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 1s 894us/step - loss: 0.4909 - acc: 0.7957\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - 1s 917us/step - loss: 0.4859 - acc: 0.7993\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - 1s 898us/step - loss: 0.4791 - acc: 0.8008\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - 1s 892us/step - loss: 0.4747 - acc: 0.8032\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - 1s 912us/step - loss: 0.4715 - acc: 0.8033\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - 1s 912us/step - loss: 0.4647 - acc: 0.8064\n",
      "Epoch 32/100\n",
      "774/774 [==============================] - 1s 939us/step - loss: 0.4605 - acc: 0.8109\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - 1s 910us/step - loss: 0.4552 - acc: 0.8105\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - 1s 993us/step - loss: 0.4509 - acc: 0.8136\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - 1s 942us/step - loss: 0.4490 - acc: 0.8124\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - 1s 951us/step - loss: 0.4445 - acc: 0.8158\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - 1s 903us/step - loss: 0.4383 - acc: 0.8174\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.4331 - acc: 0.8200\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - 1s 915us/step - loss: 0.4302 - acc: 0.8224\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - 1s 821us/step - loss: 0.4266 - acc: 0.8247\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - 1s 830us/step - loss: 0.4238 - acc: 0.8246\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - 1s 792us/step - loss: 0.4202 - acc: 0.8283\n",
      "Epoch 43/100\n",
      "  1/774 [..............................] - ETA: 0s - loss: 0.5897 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-e2dbe912f2a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 metrics=[\"acc\"])\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"acc\"])\n",
    "history = model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/194 [..............................] - ETA: 0s - loss: 0.4471 - acc: 0.8125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "194/194 [==============================] - 0s 769us/step - loss: 0.4094 - acc: 0.8335\n",
      "Loss: 0.409440279006958 - Acc: 0.8334949612617493\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss: {0} - Acc: {1}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-820af9aadf8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['acc'], label='accuracy')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00A: 0s - loss: 0.0000e+00 \n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00A: 0s - loss: 0.0000e+00 -\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "774/774 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 1/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00A: 1s - loss: 0.0000\n",
      "Epoch 56/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00A: 0s - loss: 0.0000e+00 - acc: 0\n",
      "Epoch 86/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 1/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 0.0000e+0 - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00A: 0s - loss: 0.0000e+00 \n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 0.0000e+0 - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 1/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "774/774 [==============================] - 1s 948us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "774/774 [==============================] - 1s 877us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "774/774 [==============================] - 1s 845us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "774/774 [==============================] - 1s 853us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "774/774 [==============================] - 1s 853us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "774/774 [==============================] - 1s 890us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "774/774 [==============================] - 1s 974us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "774/774 [==============================] - 1s 915us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "774/774 [==============================] - 1s 805us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "774/774 [==============================] - 1s 818us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "774/774 [==============================] - 1s 830us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "774/774 [==============================] - 1s 812us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "774/774 [==============================] - 1s 871us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "774/774 [==============================] - 1s 826us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "774/774 [==============================] - 1s 811us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "774/774 [==============================] - 1s 820us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "774/774 [==============================] - 1s 844us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "774/774 [==============================] - 1s 936us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "774/774 [==============================] - 1s 821us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "774/774 [==============================] - 1s 850us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "774/774 [==============================] - 1s 894us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "774/774 [==============================] - 1s 835us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "774/774 [==============================] - 1s 998us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "774/774 [==============================] - 1s 920us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "774/774 [==============================] - 1s 902us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "774/774 [==============================] - 1s 845us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "774/774 [==============================] - 1s 798us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "774/774 [==============================] - 1s 902us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "774/774 [==============================] - 1s 890us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "774/774 [==============================] - 1s 843us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "774/774 [==============================] - 1s 849us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "774/774 [==============================] - 1s 897us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "774/774 [==============================] - 1s 879us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "774/774 [==============================] - 1s 880us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "774/774 [==============================] - 1s 928us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "774/774 [==============================] - 1s 876us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "774/774 [==============================] - 1s 889us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "774/774 [==============================] - 1s 902us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "774/774 [==============================] - 1s 920us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "774/774 [==============================] - 1s 938us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 1s 892us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "774/774 [==============================] - 1s 925us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "774/774 [==============================] - 1s 836us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "774/774 [==============================] - 1s 836us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "774/774 [==============================] - 1s 838us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "774/774 [==============================] - 1s 826us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "774/774 [==============================] - 1s 836us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "774/774 [==============================] - 1s 857us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "774/774 [==============================] - 1s 817us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "774/774 [==============================] - 1s 934us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "774/774 [==============================] - 1s 926us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "774/774 [==============================] - 1s 832us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "774/774 [==============================] - 1s 848us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "774/774 [==============================] - 1s 865us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "774/774 [==============================] - 1s 834us/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 24744\n  y sizes: 24743\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-2dbdb1f163de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0my_train_data_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 24744\n  y sizes: 24743\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "list_training_error = []\n",
    "list_testing_error = []\n",
    "\n",
    "#MAKING SURE DATA TYPE ARE CORRECT\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "Y_train = np.asarray(Y_train).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    inputs = KL.Input(shape=(split_columns, X_train.shape[2]))\n",
    "    x = KL.SimpleRNN(100, activation ='relu')(inputs) \n",
    "    outputs = KL.Dense(1, activation=\"softmax\")(x)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    model.fit(X_train, Y_train, epochs=100)\n",
    "    \n",
    "    y_train_data_pred = model.predict(X_train)\n",
    "    y_test_data_pred = model.predict(X_test)\n",
    "    fold_training_error = mean_absolute_error(y_train, y_train_data_pred) \n",
    "    fold_testing_error = mean_absolute_error(y_test, y_test_data_pred)\n",
    "    list_training_error.append(fold_training_error)\n",
    "    list_testing_error.append(fold_testing_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1, kf.get_n_splits()), np.array(list_training_error).ravel(), 'o-')\n",
    "plt.xlabel('number of fold')\n",
    "plt.ylabel('training error')\n",
    "plt.title('Training error across folds')\n",
    "plt.tight_layout()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, kf.get_n_splits()), np.array(list_testing_error).ravel(), 'o-')\n",
    "plt.xlabel('number of fold')\n",
    "plt.ylabel('testing error')\n",
    "plt.title('Testing error across folds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
